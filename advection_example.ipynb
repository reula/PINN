{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006ba2f2",
   "metadata": {},
   "source": [
    "# 1D Wave Equation with Dirichlet boundary conditions\n",
    "\n",
    "### From the wave example in NeuralPDE\n",
    "\n",
    "Let's solve this 1-dimensional wave or advection equation: with initial conditions $u(x,0) = x(1-x)$\n",
    "\n",
    "```math\n",
    "\\begin{align*}\n",
    "∂_t u(x, t) = c ∂_x u(x, t) \\quad & \\textsf{for all } 0 < x < 1 \\text{ and } t > 0 \\, , \\\\\n",
    "u(x, 0) = x (1-x)     \\quad & \\textsf{for all } 0 < x < 1 \\, , \\\\\n",
    "\\end{align*}\n",
    "```\n",
    "We try some boundary conditions to see whether ir works ok, and what one gets with wrong boundary values.\n",
    "with grid discretization `dx = 0.1` and physics-informed neural networks.\n",
    "With boundary conditions in both sides\n",
    "(a problem ill posed)\n",
    "```math\n",
    "u(0, t) = u(1, t) = 0 \\quad  \\textsf{for all } t > 0 \\, ,\n",
    "```\n",
    "It converges to something it is not a solution.\n",
    "\n",
    "With \n",
    "```math\n",
    "u(0, t) = 0 \\quad  \\textsf{for all } t > 0 \\, ,\n",
    "```\n",
    "we get the correct solution.\n",
    "\n",
    "With \n",
    "```math\n",
    "u(1, t) = 0 \\quad  \\textsf{for all } t > 0 \\, ,\n",
    "```\n",
    "\n",
    "Also converges to something that is not a solution. So one should be worried that in complex situations one does not get into something which is not a solution and nevertheless the lost function is very small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e404a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NeuralPDE, Lux, Optimization, OptimizationOptimJL\n",
    "using ModelingToolkit: Intervals \n",
    "using IntervalSets\n",
    "using Plots, Printf\n",
    "\n",
    "@parameters t, x\n",
    "@variables u(..)\n",
    "Dx = Differential(x)\n",
    "Dt = Differential(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2D PDE\n",
    "C = 1\n",
    "eq = Dt(u(t, x)) ~ C * Dx(u(t, x))\n",
    "\n",
    "# Initial and boundary conditions\n",
    "# Ill posed bc. With this one the wrong boundary becomes negative and then goes to zero, the other boundary stays zero.\n",
    "#=\n",
    "bcs = [u(t, 0) ~ 0.0,# for all t > 0\n",
    "    u(t, 1) ~ 0.0,# for all t > 0\n",
    "    u(0, x) ~ x * (1.0 - x)] #for all 0 < x < 1\n",
    "=# \n",
    "\n",
    "# correct boundary condition.\n",
    "# #=\n",
    "bcs = [u(t, 1) ~ 0.0,# for all t > 0\n",
    "    u(0, x) ~ x * (1.0 - x)] #for all 0 < x < 1\n",
    "# =#\n",
    "# incorrect also with this it goes to zero in a few cycles.\n",
    "#=\n",
    "bcs = [u(t, 0) ~ 0.0,# for all t > 0\n",
    "    u(0, x) ~ x * (1.0 - x)] #for all 0 < x < 1\n",
    "=#\n",
    "\n",
    "# Space and time domains\n",
    "domains = [t ∈ Interval(0.0, 8.0),\n",
    "    x ∈ Interval(0.0, 1.0)]\n",
    "# Discretization\n",
    "dx = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a172a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural network\n",
    "chain = Chain(Dense(2, 16, σ), Dense(16, 16, σ), Dense(16, 1))\n",
    "\n",
    "points = 20000\n",
    "bcs_points = 300\n",
    "strategy = GridTraining(dx)\n",
    "#strategy = NeuralPDE.StochasticTraining(points, bcs_points = bcs_points)\n",
    "#=\n",
    "strategy = NeuralPDE.QuasiRandomTraining(points, bcs_points = points,\n",
    "                            sampling_alg = NeuralPDE.LatinHypercubeSample(), resampling = true,\n",
    "                            minibatch = 100)\n",
    "=#\n",
    "discretization = PhysicsInformedNN(chain, strategy)\n",
    "\n",
    "@named pde_system = PDESystem(eq, bcs, domains, [t, x], [u(t, x)])\n",
    "prob = discretize(pde_system, discretization)\n",
    "\n",
    "loss_correct = []\n",
    "#loss_incorrect = []\n",
    "#loss_QR50 = []\n",
    "#loss_QR100 = []\n",
    "#loss_GT = []\n",
    "\n",
    "callback = function (p, l)\n",
    "    println(\"Current loss is: $l\")\n",
    "    push!(loss_correct, l)\n",
    "    #push!(loss_incorrect, l)\n",
    "    #push!(loss_QR100, l)\n",
    "    #push!(loss_GT, l)\n",
    "    return false\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimizer\n",
    "opt = OptimizationOptimJL.BFGS()\n",
    "res = Optimization.solve(prob, opt; callback, maxiters = 2000)\n",
    "phi = discretization.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(log10.(loss_QR50),label=\"QuasiRandom, 20000, 300, MB=50\", title=\"Different sampling methods\")\n",
    "plot!(log10.(loss_QR100),label=\"QuasiRandom, 20000, 300, MB=100\")\n",
    "plot!(log10.(loss_GT),label=\"Grid, dx=0.1\")\n",
    "#savefig(\"advection_loss_strategies_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2087462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(log10.(loss_correct),label=\"correct bc\")\n",
    "#plot(log10.(loss_incorrect), label=\"incorrect bc\")\n",
    "#savefig(\"loss_advection_bc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4aaf4",
   "metadata": {},
   "source": [
    "![loss for different boundary conditions](loss_advection_bc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18758373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ts, xs = [infimum(d.domain):dx:supremum(d.domain) for d in domains]\n",
    "ts = collect(0.0:dx:20.0)\n",
    "xs = collect(0.0:dx:1.0)\n",
    "function analytic_sol_func(t, x)\n",
    "    v = (x+t)*(1 - (x+t))\n",
    "    if v >= 0\n",
    "        return v\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0038fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u_predict = reshape([first(phi([t, x], res.u)) for x in xs for t in ts],\n",
    "    (length(ts), length(xs)))\n",
    "u_real = reshape([analytic_sol_func(t, x) for x in xs for t in ts],\n",
    "    (length(ts), length(xs)))\n",
    "\n",
    "diff_u = abs.(u_predict .- u_real)\n",
    "\n",
    "p1 = plot(xs, ts, u_real, linetype = :contourf, title = \"analytic\")#, aspectratio=1);\n",
    "p2 = plot(xs, ts, u_predict, linetype = :contourf, title = \"predict\")#, aspectratio=1);\n",
    "p3 = plot(xs, ts, diff_u, linetype = :contourf, title = \"error\");\n",
    "plot(p1, p2, p3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ae75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ts[6]\n",
    "sol_p = [first(phi([t, x], res.u)) for x in xs]\n",
    "plot(xs,sol_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for t in ts\n",
    "    @info \"Time $t...\"\n",
    "    sol_p = [first(phi([t, x], res.u)) for x in xs]\n",
    "    plot(ylims = [-0.1, 0.6])\n",
    "    title = @sprintf(\"t = %.3f\", t) \n",
    "    plot!(xs,sol_p, label=\"predicted\", title=title)\n",
    "end\n",
    "gif(anim, \"advection.gif\", fps = 200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.7",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
